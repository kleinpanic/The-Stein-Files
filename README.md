# Epstein Files Public Document Library

**Live Site:** [https://kleinpanic.github.io/The-Stein-Files/](https://kleinpanic.github.io/The-Stein-Files/)

This repository collects and preserves officially released Epstein-related public documents from U.S. federal government sources or clearly official court releases, and publishes a searchable static site.

## âœ¨ Features

### Search & Discovery
- **Advanced Search Modes**: Full-text (fuzzy), person search, location search, file number lookup
- **Smart Filters**: Multi-select sources/years/tags, date ranges, file size, page count, document quality, OCR status
- **Auto-Tagging**: Documents automatically tagged by keywords, people mentioned, locations, date ranges, and document types
- **Related Documents**: Each result shows up to 3 related documents based on case numbers, people, locations, and dates
- **Search Suggestions**: Autocomplete adapts to current search mode

### Document Organization
- **Person Profiles**: Dedicated pages for major people (5+ mentions) with timeline, document breakdown, and full document lists
- **Emails Section**: Browse 149+ emails with From/To/Subject metadata extraction and Epstein-specific filtering
- **Document Categories**: Correspondence, depositions, legal filings, flight logs, evidence photos, and more

### Enhanced Metadata
- **Character Extraction**: 194 person names, 417 locations, 15 case numbers extracted from documents
- **OCR Applied**: 279 image-only PDFs processed with OCR for searchable text
- **Quality Scores**: Document text quality rated on 0-100 scale
- **Document Classification**: Text, image, or hybrid PDFs with confidence indicators

### User Experience
- **CSV Export**: Export search results with full metadata for offline analysis
- **Keyboard Shortcuts**: Ctrl+K to focus search, Esc to clear
- **Share Search**: Copy current search/filter state URL to clipboard
- **Mobile Optimized**: Swipe-up filter drawer, WCAG 2.1 AAA touch targets, optimized PDF rendering
- **PDF Viewer**: In-page PDF viewing with GitHub LFS integration (graceful fallback when bandwidth limited)

### Statistics & Analytics
- **Stats Dashboard**: Timeline visualizations, document type breakdowns, quality distributions, source-level analytics
- **Coverage Metrics**: Track OCR status, categorization progress, and collection completeness

## Sources
See `docs/SOURCES.md` for the canonical list of official upstream sources.

## Integrity
- Raw files are stored exactly as released under `data/raw/`.
- Derived artifacts (text, index) are stored under `data/derived/`.

## How to run locally

### Requirements
- Python 3.11+
- Node.js 20+
- Optional: `pdftotext` from poppler

### Setup
```bash
make setup
```

### Common commands
- `make ingest` to download/update official releases
- `make extract` to extract text and build the search index
- `make build` to build the static site into `dist/`
- `make test` to run validation checks
- `make check-links` to verify configured source URLs are not stale
- `make verify-doj` to check DOJ Epstein endpoints using the current cookie jar
- `make dev` to build then serve `dist/` locally

### Ingest caps
You can override download limits per run:
```bash
EPPIE_MAX_DOWNLOADS_PER_SOURCE=30 EPPIE_MAX_BYTES_PER_RUN=250000000 make ingest
```

### Throttling and retries
Ingest defaults to a polite rate with exponential backoff. You can tune it with:
- `EPPIE_REQUESTS_PER_SECOND` (default 1.5)
- `EPPIE_MAX_CONCURRENCY` (default 2, controls HTTP connection pool size)
- `EPPIE_RETRY_MAX` (default 5)
- `EPPIE_BACKOFF_BASE_SECONDS` (default 1.0)
- `EPPIE_TIME_BUDGET_SECONDS` (optional hard time limit per run)

### DOJ Epstein Library access (cookies)
Some DOJ Epstein Library pages are age-gated. Use the interactive auth helper once to
capture a local cookie jar:
```bash
make auth-doj
```
The first run will download the Playwright Chromium browser if needed.
Cookies are stored locally in `.secrets/justice.gov.cookies.txt` and are not committed.
The auth helper also writes:
- `.secrets/justice.gov.cookies.json`
- `.secrets/doj.storage-state.json`
`make ingest` will automatically use the `.txt` jar when present.
You can override the jar explicitly:
```bash
EPPIE_COOKIE_JAR=/path/to/cookies.txt make ingest
```

### Derived outputs
`data/derived/` is treated as a build artifact and is generated by `make extract` or `make build`.

### Mirror mode (optional)
By default, the site links to official source URLs and does not bundle raw PDFs into `dist/`.
To build a fully mirrored site that includes raw files, set:
```bash
EPPIE_MIRROR_MODE=1 make build
```
Use with caution; mirrored builds can be large and may exceed GitHub Pages limits.

### Serve the site
`make dev` builds the site and starts a local static server at `http://localhost:8000`.

## Build pipeline
GitHub Actions runs a scheduled ingestion workflow that downloads new releases (if any), extracts text, rebuilds the site, validates integrity, and commits updates. Pushes to the default branch deploy to GitHub Pages.

## License
Code is MIT licensed. Documents remain under their original terms as published by the source authority.
